


We developed an algorithm for digitizing users design on fabric. It uses computer vision libraries in OpenCV for detecting shapes and colors, and the AR Marker library\footnote{https://pypi.python.org/pypi/ar-markers/0.4.1} to generate and detect markers on the color template, hoop, and sensor stickers. Based on the markers in the input image, our algorithm distinguishes between a \textit{color assignment image}, which contains the color template markers, and a \textit{design image}, which contains the hoop markers and, optionally, sensor markers. Figure \ref{fig:Pipeline} describes our sketch digitization pipeline, part of S\&S PC app. Our app send the output of the pipeline, the \textit{embroidery stack}, to the embroidery software to be converted to patterns, and then to the embroidery machine for stitching. %The pipeline starts after the user captures a picture of her design.


\subsection{Marker Detection and Cropping}
The algorithm imports the input image from a cloud storage and converts it from the RGB- to the HSV-colorspace. The HSV space allows defining color ranges, making it more suitable for processing images where color variability is expected. Next, it detects the markers in the image. In total, it distinguishes 12 markers: 6 on the color template, 2 on the fabric hoop, 3 on Shield Stickers, and 1 on the Sensor Sticker. In the \textit{design image}, the algorithm uses the hoop markers to 1. create a rotation matrix to rotate the sketch, and 2. create a cropping mask to crop the sketch from the image. 

\subsection{Reprocessing}
Our algorithm adjusts the gamma, and increases the sharpness, contrast, and exposure of the input image. These operations were selected carefully to enhance color contrast, remove noise and artefacts, and improve the edges of the sketched shapes. 
%We assume a uniform background and illumination 


\subsection{Color Detection and Layering}
\textit{Color assignment image}. The algorithm scans the lines next to each color marker, reading the Hue, Saturation, and Value of each pixel. Spikes in the Hue channel indicate color change. It calculate the mean HSV values around each spike. Using these values we define color ranges and associate them with the nearest color marker. The color ranges determine the color palette, which is used in \textit{design images}. 
%If the algorithm fails to detect the user's color palette, the user can repeat the process using alternative fabric pen colors. 
%+color assignment provides the user with the freedom on color choice
%+it detects colors as they appear on the fabric background


\textit{Design image}. The algorithm thresholds the image using the user's color palette, removes Component Stickers by filtering for \textit{sticker colors}, and creates the following single-color layers:
\begin{enumerate}
\itemsep-0.2em 
   % \item \textit{Sticker colors} masks --- Filters for Component Stickers to remove them from the image. % and leaves white space in their place.
    \item Trace layer --- \textit{trace color} mask: hand-sketched traces and sensors, including traces that extend from stickers. %All are stored in the trace layer.
    \item Insulation layer --- \textit{insulation color} mask: insulated traces.
    \item Art layers --- \textit{art colors} masks: artwork lines and shapes.
\end{enumerate}
 

After color detection is complete, S\&S PC app displays the digitized input image---\textit{color assignment image} or \textit{design image}---on the PC screen and provides the user with sliders to optionally tune the upper and lower bounds of the HSV channels. The user sees the results of adjusting the sliders on the screen in real-time. %The user can confirm color detection, or repeat the process using, e.g., alternative pen colors or better lighting, to achieve better detection. 
To enable incremental design, the algorithm subtracts the input \textit{design image} from the last user-confirmed image before performing color detection.

\subsection{Embroidery Stack Generation and Stitch Mapping}
In the \textit{design image,}, the algorithm creates the necessary stacks for insulated objects and Embroidery Stickers, as previously described. The combination of layers from the selection masks and the stacks is called the \textit{embroidery stack} (see the last step in Fig.\ \ref{fig:Pipeline}). S\&S PC app sequences the layers and sends them to the embroidery software in the following order: trace (red), grid (purple), insulation (green), bridge (orange), then art layers (blue), together with the  color--to-- stitch mapping. The embroidery machine stitches the layers in sequence. The user uses the color of each layer, which appear on the machine's display, to resolve the type of thread required.

 %duplicates the insulation layer and tints it with the system's \textit{grid color}, generating an \textit{insulation stack}. It replaces each sensor marker with a \textit{shield stack} composed of a grid, insulation, and bridge layers, each tinted accordingly. Finally, the algorithm merges and sequences the layers from the selection masks and the stacks based on color. The result is an \textit{embroidery stack} composed of a trace, grid, insulation, bridge, and art layers. The layers are sent to the embroidery software to be converted to embroidery patterns with the corresponding stitch types. S\&S PC app sends the patterns to the embroidery machine. The user stitches the patterns in sequence and uses the color of each pattern to resolve the type of thread it requires.












